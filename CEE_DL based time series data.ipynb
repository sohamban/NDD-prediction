{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349da7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import datasets\n",
    "from nilearn import maskers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn import plotting\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f742f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ADHD file \n",
    "adhd_filename = pd.read_csv(\"E:/ADHD200/path_label_motion_spatial.csv\")\n",
    "adhd_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4acbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_pos=[]\n",
    "adhd_neg=[]\n",
    "\n",
    "for i in range(len(adhd_filename)):\n",
    "    if(adhd_filename['Label'][i]==0):\n",
    "        adhd_neg.append(adhd_filename['motion_spatial'][i])\n",
    "    else:\n",
    "        adhd_pos.append(adhd_filename['motion_spatial'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ea3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"E:/ADHD200/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb05952",
   "metadata": {},
   "source": [
    "# Dictionary learning  component decide to generate ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fa313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_img\n",
    "from nilearn.masking import compute_multi_epi_mask\n",
    "from nilearn.decomposition import DictLearning\n",
    "\n",
    "# Resample all images to a common FOV\n",
    "reference_img = resample_img(adhd_motion_spatial[0], target_affine=None, target_shape=None)\n",
    "reference_img_shape = reference_img.shape[:3]  # get the first three dimensions\n",
    "reference_img_affine = reference_img.affine\n",
    "\n",
    "adhd_resampled = []\n",
    "for img in adhd_motion_spatial[0:100]:\n",
    "    img_resampled = resample_img(img, target_affine=reference_img.affine, target_shape=reference_img_shape)\n",
    "    adhd_resampled.append(img_resampled)\n",
    "\n",
    "# Compute a common mask for all resampled images\n",
    "mask_img = compute_multi_epi_mask(adhd_resampled, threshold=0.3)\n",
    "\n",
    "# Fit the ICA model using the resampled images and the common mask\n",
    "dict_learning= DictLearning(\n",
    "    n_components=20,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=2,\n",
    "    verbose=1,\n",
    "    random_state=0,\n",
    "    n_epochs=1,\n",
    "    mask_strategy=\"whole-brain-template\",\n",
    "    mask=mask_img\n",
    ")\n",
    "\n",
    "dict_learning.fit(adhd_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2528dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictlearning_components_img = dict_learning.components_img_\n",
    "# components_img is a Nifti Image object, and can be saved to a file with\n",
    "# the following line:\n",
    "dictlearning_components_img.to_filename('E:/ADHD200/dictlearning_components_img.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "# load the .nii.gz file\n",
    "dictlearning_components_img = nib.load('E:/ADHD200/dictlearning_components_img.nii.gz')\n",
    "\n",
    "# get the data as a numpy array\n",
    "dictlearning_components_numpy= dictlearning_components_img.get_fdata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06207d05",
   "metadata": {},
   "source": [
    "# Print all dictionary components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19055de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_prob_atlas\n",
    "# Plot all DL components together\n",
    "plot_prob_atlas(\n",
    "    dictlearning_components_img, title=\"All DictLearning components\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed8c2c",
   "metadata": {},
   "source": [
    "# Generate region extrator for DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.regions import RegionExtractor\n",
    "\n",
    "extractor = RegionExtractor(\n",
    "    dictlearning_components_img,\n",
    "    threshold=0.5,\n",
    "    thresholding_strategy=\"ratio_n_voxels\",\n",
    "    extractor=\"local_regions\",\n",
    "    standardize=True,\n",
    "    min_region_size=1350,\n",
    ")\n",
    "# Just call fit() to process for regions extraction\n",
    "extractor.fit()\n",
    "# Extracted regions are stored in regions_img_\n",
    "regions_extracted_img = extractor.regions_img_\n",
    "# Each region index is stored in index_\n",
    "regions_index = extractor.index_\n",
    "# Total number of regions extracted\n",
    "n_regions_extracted = regions_extracted_img.shape[-1]\n",
    "\n",
    "# Visualization of region extraction results\n",
    "# title = (\n",
    "#     \"%d regions are extracted from %d components.\"\n",
    "#     \"\\nEach separate color of region indicates extracted region\"\n",
    "#     % (n_regions_extracted, 8)\n",
    "\n",
    "plotting.plot_prob_atlas(\n",
    "    regions_extracted_img, view_type=\"filled_contours\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88524c",
   "metadata": {},
   "source": [
    "# Display all atoms or components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(dictlearning_components_img)):\n",
    "    plot_stat_map(\n",
    "        cur_img,\n",
    "        display_mode=\"z\",\n",
    "        title=f\"Comp {int(i)}\",\n",
    "        cut_coords=1,\n",
    "        colorbar=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7cc74",
   "metadata": {},
   "source": [
    "# Time series data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27541e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "all_data=[]\n",
    "for filename  in adhd_motion_spatial:\n",
    "    time_series = extractor.transform(filename)\n",
    "    all_data.append(time_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d545df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"E:/ADHD200/dict_learning_times_series_905.npy\",all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
