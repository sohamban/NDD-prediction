{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75663a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a5e79",
   "metadata": {},
   "source": [
    "# PLV based  adjacency matrix loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from the drive location\n",
    "X= np.load(\"E:/ADHD200/plv_corr/all_plv_adjacency.npy\")\n",
    "Y= np.load(\"E:/ADHD200/label_905.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d64f3",
   "metadata": {},
   "source": [
    "# GCN based classification on PLV based BFC with pytorch geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "import time\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "# Create the edge index for the fully connected graph\n",
    "num_rois = X.shape[1]\n",
    "row, col = [], []\n",
    "for i in range(num_rois):\n",
    "    for j in range(i + 1, num_rois):\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "\n",
    "# Create a custom GCN model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, num_rois, num_psd_features, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(num_psd_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.conv3 = GCNConv(64, 32)\n",
    "        self.fc = nn.Linear(num_rois * 32, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "num_psd_features = X.shape[2]  # Number of PSD features\n",
    "num_classes = 2  # Binary classification\n",
    "model = GCNModel(num_rois, num_psd_features, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders for batch training\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for all folds\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "y_prob_all = []\n",
    "\n",
    "# Mean ROC curve data\n",
    "mean_tpr = 0.0\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n=================== Fold {fold + 1}/{num_folds} ===================\\n\")\n",
    "    \n",
    "    # Start timer for the entire fold\n",
    "    fold_start_time = time.time()\n",
    "\n",
    "    # Split the data into training+validation and testing sets for this fold\n",
    "    x_train_val, x_test = x_tensor[train_val_idx], x_tensor[test_idx]\n",
    "    y_train_val, y_test = y_tensor[train_val_idx], y_tensor[test_idx]\n",
    "    \n",
    "    # Further split the training data into 80% training and 20% validation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_train_val, y_train_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the data and data loaders for this fold\n",
    "    train_data = Data(x=x_train, edge_index=edge_index, y=y_train)\n",
    "    val_data = Data(x=x_val, edge_index=edge_index, y=y_val)\n",
    "    test_data = Data(x=x_test, edge_index=edge_index, y=y_test)\n",
    "    \n",
    "    train_loader = DataLoader([train_data], batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader([val_data], batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader([test_data], batch_size=16, shuffle=False)\n",
    "\n",
    "    # Track time for training, validation, and testing separately\n",
    "    train_time = 0\n",
    "    val_time = 0\n",
    "    test_time = 0\n",
    "\n",
    "    # Train the model for this fold\n",
    "    num_epochs = 100\n",
    "    best_val_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        epoch_start_time = time.time()  # Start time for this epoch\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(output, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_time += time.time() - epoch_start_time  # Add training time for this epoch\n",
    "\n",
    "        # Print the loss value for the current epoch\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_start_time = time.time()  # Start validation time\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                output = model(batch.x, batch.edge_index)\n",
    "                _, val_predicted_labels = torch.max(output, 1)\n",
    "                val_correct += (val_predicted_labels == batch.y).sum().item()\n",
    "                val_total += batch.y.size(0)\n",
    "        val_time += time.time() - val_start_time  # Add validation time\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy  # Save the best validation accuracy\n",
    "\n",
    "    print(f\"Fold {fold + 1} Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_start_time = time.time()  # Start testing time\n",
    "    with torch.no_grad():\n",
    "        output_test = model(x_test, edge_index)\n",
    "        _, predicted_labels = torch.max(output_test, 1)\n",
    "    test_time += time.time() - test_start_time  # Add testing time\n",
    "\n",
    "    # Calculate the accuracy for this fold\n",
    "    correct = (predicted_labels == y_test).sum().item()\n",
    "    total = y_test.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Fold {fold + 1} Test Accuracy: {accuracy:.4f}\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Calculate the AUC and ROC curve for this fold\n",
    "    output_prob = torch.softmax(output_test, dim=1)[:, 1].numpy()\n",
    "    y_prob_all.extend(output_prob)\n",
    "    auc_score = roc_auc_score(y_test.numpy(), output_prob)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    # Compute the evaluation metrics for this fold\n",
    "    conf_matrix = confusion_matrix(y_test.numpy(), predicted_labels.numpy())\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "    # Compute the ROC curve for this fold\n",
    "    fpr, tpr, _ = roc_curve(y_test.numpy(), output_prob)\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    plt.plot(fpr, tpr, alpha=0.3, label=f\"Fold {fold + 1} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "    # End timer for fold\n",
    "    fold_end_time = time.time()\n",
    "    print(f\"Training Time for Fold {fold + 1}: {train_time:.2f} seconds\")\n",
    "    print(f\"Validation Time for Fold {fold + 1}: {val_time:.2f} seconds\")\n",
    "    print(f\"Testing Time for Fold {fold + 1}: {test_time:.2f} seconds\")\n",
    "    print(f\"Total Time for Fold {fold + 1}: {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "\n",
    "# Plot the mean ROC curve\n",
    "mean_tpr /= num_folds\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=f\"Mean ROC (AUC = {np.mean(auc_scores):.2f})\", linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mean ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean and standard deviation of the evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "mean_specificity = np.mean(specificity_scores)\n",
    "std_specificity = np.std(specificity_scores)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Overall Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Overall Specificity: {mean_specificity:.4f} ± {std_specificity:.4f}\")\n",
    "print(f\"Overall AUC: {mean_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10ee5b",
   "metadata": {},
   "source": [
    "# Increase feature size from 128 to 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23520ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "# Create the edge index for the fully connected graph\n",
    "num_rois = X.shape[1]\n",
    "row, col = [], []\n",
    "for i in range(num_rois):\n",
    "    for j in range(i + 1, num_rois):\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "\n",
    "# Create a custom GCN model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, num_rois, num_psd_features, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        #total three GCN layers\n",
    "        self.conv1 = GCNConv(num_psd_features, 256)\n",
    "        self.conv2 = GCNConv(256, 64)\n",
    "        self.conv3 = GCNConv(64, 32)\n",
    "        self.fc = nn.Linear(num_rois * 32, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # total three hidden layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "num_psd_features = X.shape[2]  # Number of PSD features\n",
    "num_classes = 2  # Binary classification\n",
    "model = GCNModel(num_rois, num_psd_features, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders for batch training\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for all folds\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "y_prob_all = []\n",
    "\n",
    "# Mean ROC curve data\n",
    "mean_tpr = 0.0\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n=================== Fold {fold + 1}/{num_folds} ===================\\n\")\n",
    "    \n",
    "    # Start timer for the entire fold\n",
    "    fold_start_time = time.time()\n",
    "\n",
    "    # Split the data into training+validation and testing sets for this fold\n",
    "    x_train_val, x_test = x_tensor[train_val_idx], x_tensor[test_idx]\n",
    "    y_train_val, y_test = y_tensor[train_val_idx], y_tensor[test_idx]\n",
    "    \n",
    "    # Further split the training data into 80% training and 20% validation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_train_val, y_train_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the data and data loaders for this fold\n",
    "    train_data = Data(x=x_train, edge_index=edge_index, y=y_train)\n",
    "    val_data = Data(x=x_val, edge_index=edge_index, y=y_val)\n",
    "    test_data = Data(x=x_test, edge_index=edge_index, y=y_test)\n",
    "    \n",
    "    train_loader = DataLoader([train_data], batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader([val_data], batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader([test_data], batch_size=16, shuffle=False)\n",
    "\n",
    "    # Track time for training, validation, and testing separately\n",
    "    train_time = 0\n",
    "    val_time = 0\n",
    "    test_time = 0\n",
    "\n",
    "    # Train the model for this fold\n",
    "    num_epochs = 100\n",
    "    best_val_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        epoch_start_time = time.time()  # Start time for this epoch\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(output, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_time += time.time() - epoch_start_time  # Add training time for this epoch\n",
    "\n",
    "        # Print the loss value for the current epoch\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_start_time = time.time()  # Start validation time\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                output = model(batch.x, batch.edge_index)\n",
    "                _, val_predicted_labels = torch.max(output, 1)\n",
    "                val_correct += (val_predicted_labels == batch.y).sum().item()\n",
    "                val_total += batch.y.size(0)\n",
    "        val_time += time.time() - val_start_time  # Add validation time\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy  # Save the best validation accuracy\n",
    "\n",
    "    print(f\"Fold {fold + 1} Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_start_time = time.time()  # Start testing time\n",
    "    with torch.no_grad():\n",
    "        output_test = model(x_test, edge_index)\n",
    "        _, predicted_labels = torch.max(output_test, 1)\n",
    "    test_time += time.time() - test_start_time  # Add testing time\n",
    "\n",
    "    # Calculate the accuracy for this fold\n",
    "    correct = (predicted_labels == y_test).sum().item()\n",
    "    total = y_test.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Fold {fold + 1} Test Accuracy: {accuracy:.4f}\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Calculate the AUC and ROC curve for this fold\n",
    "    output_prob = torch.softmax(output_test, dim=1)[:, 1].numpy()\n",
    "    y_prob_all.extend(output_prob)\n",
    "    auc_score = roc_auc_score(y_test.numpy(), output_prob)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    # Compute the evaluation metrics for this fold\n",
    "    conf_matrix = confusion_matrix(y_test.numpy(), predicted_labels.numpy())\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "    # Compute the ROC curve for this fold\n",
    "    fpr, tpr, _ = roc_curve(y_test.numpy(), output_prob)\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    plt.plot(fpr, tpr, alpha=0.3, label=f\"Fold {fold + 1} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "    # End timer for fold\n",
    "    fold_end_time = time.time()\n",
    "    print(f\"Training Time for Fold {fold + 1}: {train_time:.2f} seconds\")\n",
    "    print(f\"Validation Time for Fold {fold + 1}: {val_time:.2f} seconds\")\n",
    "    print(f\"Testing Time for Fold {fold + 1}: {test_time:.2f} seconds\")\n",
    "    print(f\"Total Time for Fold {fold + 1}: {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "\n",
    "# Plot the mean ROC curve\n",
    "mean_tpr /= num_folds\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=f\"Mean ROC (AUC = {np.mean(auc_scores):.2f})\", linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mean ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean and standard deviation of the evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "mean_specificity = np.mean(specificity_scores)\n",
    "std_specificity = np.std(specificity_scores)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Overall Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Overall Specificity: {mean_specificity:.4f} ± {std_specificity:.4f}\")\n",
    "print(f\"Overall AUC: {mean_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1645da8",
   "metadata": {},
   "source": [
    "# Increase GCN layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4068a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "# Create the edge index for the fully connected graph\n",
    "num_rois = X.shape[1]\n",
    "row, col = [], []\n",
    "for i in range(num_rois):\n",
    "    for j in range(i + 1, num_rois):\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "\n",
    "# Create a custom GCN model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, num_rois, num_psd_features, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        #total three GCN layers\n",
    "        self.conv1 = GCNConv(num_psd_features, 256)\n",
    "        self.conv2 = GCNConv(256, 64)\n",
    "        self.conv3 = GCNConv(64, 64)\n",
    "        self.conv3 = GCNConv(64, 32)\n",
    "        self.fc = nn.Linear(num_rois * 32, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # total three hidden layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "num_psd_features = X.shape[2]  # Number of PSD features\n",
    "num_classes = 2  # Binary classification\n",
    "model = GCNModel(num_rois, num_psd_features, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders for batch training\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for all folds\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "y_prob_all = []\n",
    "\n",
    "# Mean ROC curve data\n",
    "mean_tpr = 0.0\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n=================== Fold {fold + 1}/{num_folds} ===================\\n\")\n",
    "    \n",
    "    # Start timer for the entire fold\n",
    "    fold_start_time = time.time()\n",
    "\n",
    "    # Split the data into training+validation and testing sets for this fold\n",
    "    x_train_val, x_test = x_tensor[train_val_idx], x_tensor[test_idx]\n",
    "    y_train_val, y_test = y_tensor[train_val_idx], y_tensor[test_idx]\n",
    "    \n",
    "    # Further split the training data into 80% training and 20% validation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_train_val, y_train_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the data and data loaders for this fold\n",
    "    train_data = Data(x=x_train, edge_index=edge_index, y=y_train)\n",
    "    val_data = Data(x=x_val, edge_index=edge_index, y=y_val)\n",
    "    test_data = Data(x=x_test, edge_index=edge_index, y=y_test)\n",
    "    \n",
    "    train_loader = DataLoader([train_data], batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader([val_data], batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader([test_data], batch_size=16, shuffle=False)\n",
    "\n",
    "    # Track time for training, validation, and testing separately\n",
    "    train_time = 0\n",
    "    val_time = 0\n",
    "    test_time = 0\n",
    "\n",
    "    # Train the model for this fold\n",
    "    num_epochs = 100\n",
    "    best_val_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        epoch_start_time = time.time()  # Start time for this epoch\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(output, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_time += time.time() - epoch_start_time  # Add training time for this epoch\n",
    "\n",
    "        # Print the loss value for the current epoch\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_start_time = time.time()  # Start validation time\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                output = model(batch.x, batch.edge_index)\n",
    "                _, val_predicted_labels = torch.max(output, 1)\n",
    "                val_correct += (val_predicted_labels == batch.y).sum().item()\n",
    "                val_total += batch.y.size(0)\n",
    "        val_time += time.time() - val_start_time  # Add validation time\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy  # Save the best validation accuracy\n",
    "\n",
    "    print(f\"Fold {fold + 1} Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_start_time = time.time()  # Start testing time\n",
    "    with torch.no_grad():\n",
    "        output_test = model(x_test, edge_index)\n",
    "        _, predicted_labels = torch.max(output_test, 1)\n",
    "    test_time += time.time() - test_start_time  # Add testing time\n",
    "\n",
    "    # Calculate the accuracy for this fold\n",
    "    correct = (predicted_labels == y_test).sum().item()\n",
    "    total = y_test.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Fold {fold + 1} Test Accuracy: {accuracy:.4f}\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Calculate the AUC and ROC curve for this fold\n",
    "    output_prob = torch.softmax(output_test, dim=1)[:, 1].numpy()\n",
    "    y_prob_all.extend(output_prob)\n",
    "    auc_score = roc_auc_score(y_test.numpy(), output_prob)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    # Compute the evaluation metrics for this fold\n",
    "    conf_matrix = confusion_matrix(y_test.numpy(), predicted_labels.numpy())\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "    # Compute the ROC curve for this fold\n",
    "    fpr, tpr, _ = roc_curve(y_test.numpy(), output_prob)\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    plt.plot(fpr, tpr, alpha=0.3, label=f\"Fold {fold + 1} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "    # End timer for fold\n",
    "    fold_end_time = time.time()\n",
    "    print(f\"Training Time for Fold {fold + 1}: {train_time:.2f} seconds\")\n",
    "    print(f\"Validation Time for Fold {fold + 1}: {val_time:.2f} seconds\")\n",
    "    print(f\"Testing Time for Fold {fold + 1}: {test_time:.2f} seconds\")\n",
    "    print(f\"Total Time for Fold {fold + 1}: {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "\n",
    "# Plot the mean ROC curve\n",
    "mean_tpr /= num_folds\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=f\"Mean ROC (AUC = {np.mean(auc_scores):.2f})\", linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mean ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean and standard deviation of the evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "mean_specificity = np.mean(specificity_scores)\n",
    "std_specificity = np.std(specificity_scores)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Overall Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Overall Specificity: {mean_specificity:.4f} ± {std_specificity:.4f}\")\n",
    "print(f\"Overall AUC: {mean_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d3388",
   "metadata": {},
   "source": [
    "# Correlation based adjacency matrix loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from the drive location\n",
    "X= np.load(\"E:/ADHD200/plv_corr/all_corr_adjacency.npy\")\n",
    "Y= np.load(\"E:/ADHD200/label_905.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05def969",
   "metadata": {},
   "source": [
    "# GCN based classification on Correlation based BFC with pytorch geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "x_tensor = torch.tensor(X, dtype=torch.float)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "# Create the edge index for the fully connected graph\n",
    "num_rois = X.shape[1]\n",
    "row, col = [], []\n",
    "for i in range(num_rois):\n",
    "    for j in range(i + 1, num_rois):\n",
    "        row.append(i)\n",
    "        col.append(j)\n",
    "edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "\n",
    "# Create a custom GCN model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, num_rois, num_psd_features, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        #total three GCN layers\n",
    "        self.conv1 = GCNConv(num_psd_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.conv3 = GCNConv(64, 32)\n",
    "        self.fc = nn.Linear(num_rois * 32, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # total three hidden layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "num_psd_features = X.shape[2]  # Number of PSD features\n",
    "num_classes = 2  # Binary classification\n",
    "model = GCNModel(num_rois, num_psd_features, num_classes)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders for batch training\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics for all folds\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "specificity_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "y_prob_all = []\n",
    "\n",
    "# Mean ROC curve data\n",
    "mean_tpr = 0.0\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n=================== Fold {fold + 1}/{num_folds} ===================\\n\")\n",
    "    \n",
    "    # Start timer for the entire fold\n",
    "    fold_start_time = time.time()\n",
    "\n",
    "    # Split the data into training+validation and testing sets for this fold\n",
    "    x_train_val, x_test = x_tensor[train_val_idx], x_tensor[test_idx]\n",
    "    y_train_val, y_test = y_tensor[train_val_idx], y_tensor[test_idx]\n",
    "    \n",
    "    # Further split the training data into 80% training and 20% validation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_train_val, y_train_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create the data and data loaders for this fold\n",
    "    train_data = Data(x=x_train, edge_index=edge_index, y=y_train)\n",
    "    val_data = Data(x=x_val, edge_index=edge_index, y=y_val)\n",
    "    test_data = Data(x=x_test, edge_index=edge_index, y=y_test)\n",
    "    \n",
    "    train_loader = DataLoader([train_data], batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader([val_data], batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader([test_data], batch_size=16, shuffle=False)\n",
    "\n",
    "    # Track time for training, validation, and testing separately\n",
    "    train_time = 0\n",
    "    val_time = 0\n",
    "    test_time = 0\n",
    "\n",
    "    # Train the model for this fold\n",
    "    num_epochs = 100\n",
    "    best_val_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        epoch_start_time = time.time()  # Start time for this epoch\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(output, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        train_time += time.time() - epoch_start_time  # Add training time for this epoch\n",
    "\n",
    "        # Print the loss value for the current epoch\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_start_time = time.time()  # Start validation time\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                output = model(batch.x, batch.edge_index)\n",
    "                _, val_predicted_labels = torch.max(output, 1)\n",
    "                val_correct += (val_predicted_labels == batch.y).sum().item()\n",
    "                val_total += batch.y.size(0)\n",
    "        val_time += time.time() - val_start_time  # Add validation time\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy  # Save the best validation accuracy\n",
    "\n",
    "    print(f\"Fold {fold + 1} Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    test_start_time = time.time()  # Start testing time\n",
    "    with torch.no_grad():\n",
    "        output_test = model(x_test, edge_index)\n",
    "        _, predicted_labels = torch.max(output_test, 1)\n",
    "    test_time += time.time() - test_start_time  # Add testing time\n",
    "\n",
    "    # Calculate the accuracy for this fold\n",
    "    correct = (predicted_labels == y_test).sum().item()\n",
    "    total = y_test.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Fold {fold + 1} Test Accuracy: {accuracy:.4f}\")\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Calculate the AUC and ROC curve for this fold\n",
    "    output_prob = torch.softmax(output_test, dim=1)[:, 1].numpy()\n",
    "    y_prob_all.extend(output_prob)\n",
    "    auc_score = roc_auc_score(y_test.numpy(), output_prob)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    # Compute the evaluation metrics for this fold\n",
    "    conf_matrix = confusion_matrix(y_test.numpy(), predicted_labels.numpy())\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    specificity_scores.append(specificity)\n",
    "\n",
    "    # Compute the ROC curve for this fold\n",
    "    fpr, tpr, _ = roc_curve(y_test.numpy(), output_prob)\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    plt.plot(fpr, tpr, alpha=0.3, label=f\"Fold {fold + 1} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "    # End timer for fold\n",
    "    fold_end_time = time.time()\n",
    "    print(f\"Training Time for Fold {fold + 1}: {train_time:.2f} seconds\")\n",
    "    print(f\"Validation Time for Fold {fold + 1}: {val_time:.2f} seconds\")\n",
    "    print(f\"Testing Time for Fold {fold + 1}: {test_time:.2f} seconds\")\n",
    "    print(f\"Total Time for Fold {fold + 1}: {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "\n",
    "# Plot the mean ROC curve\n",
    "mean_tpr /= num_folds\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=f\"Mean ROC (AUC = {np.mean(auc_scores):.2f})\", linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Mean ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean and standard deviation of the evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "mean_specificity = np.mean(specificity_scores)\n",
    "std_specificity = np.std(specificity_scores)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {mean_precision:.4f} ± {std_precision:.4f}\")\n",
    "print(f\"Overall Recall: {mean_recall:.4f} ± {std_recall:.4f}\")\n",
    "print(f\"Overall Specificity: {mean_specificity:.4f} ± {std_specificity:.4f}\")\n",
    "print(f\"Overall AUC: {mean_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27b603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
