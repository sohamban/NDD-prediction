{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import datasets\n",
    "from nilearn import maskers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn import plotting\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17320e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV file\n",
    "adhd_filename = pd.read_csv(\"E:/ADHD200/path_with_label.csv\")\n",
    "adhd_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_filename = pd.read_csv(\"E:/ADHD200/path_label_motion_spatial.csv\")\n",
    "adhd_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_pos=[]\n",
    "adhd_neg=[]\n",
    "\n",
    "for i in range(len(adhd_filename)):\n",
    "    if(adhd_filename['Label'][i]==0):\n",
    "        adhd_neg.append(adhd_filename['motion_spatial'][i])\n",
    "    else:\n",
    "        adhd_pos.append(adhd_filename['motion_spatial'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = adhd_filename['Label']\n",
    "label_numpy = label.to_numpy()\n",
    "label_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e256f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"E:/ADHD200/label_905.npy\",label_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_path = adhd_filename['path'].tolist()\n",
    "adhd_path\n",
    "len(adhd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea154d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_motion_spatial = adhd_filename['motion_spatial'].tolist()\n",
    "adhd_motion_spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5eec27",
   "metadata": {},
   "source": [
    "# ICA vased component decide and ROI generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cac1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import resample_img\n",
    "from nilearn.masking import compute_multi_epi_mask\n",
    "from nilearn.decomposition import CanICA\n",
    "\n",
    "# Resample all images to a common FOV\n",
    "reference_img = resample_img(adhd_motion_spatial[0], target_affine=None, target_shape=None)\n",
    "reference_img_shape = reference_img.shape[:3]  # get the first three dimensions\n",
    "reference_img_affine = reference_img.affine\n",
    "count=0;\n",
    "adhd_resampled = []\n",
    "for img in adhd_motion_spatial[0:150]:\n",
    "    img_resampled = resample_img(img, target_affine=reference_img.affine, target_shape=reference_img_shape)\n",
    "    adhd_resampled.append(img_resampled)\n",
    "    count+=1\n",
    "    print(count)\n",
    "    \n",
    "\n",
    "\n",
    "# Compute a common mask for all resampled images\n",
    "mask_img = compute_multi_epi_mask(adhd_resampled, threshold=0.3)\n",
    "\n",
    "# Fit the ICA model using the resampled images and the common mask\n",
    "# canica = CanICA(n_components=20, mask=mask_img, smoothing_fwhm=6., random_state=0)\n",
    "canica = CanICA(\n",
    "    n_components=20,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=2,\n",
    "    verbose=10,\n",
    "    mask_strategy=\"whole-brain-template\",\n",
    "    mask=mask_img, smoothing_fwhm=6,\n",
    "    random_state=0,\n",
    ")\n",
    "canica.fit(adhd_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c943c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "canica_components_img = canica.components_img_\n",
    "# components_img is a Nifti Image object, and can be saved to a file with\n",
    "# the following line:\n",
    "canica_components_img.to_filename('E:/ADHD200/canica_resting_state_905.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "# load the .nii.gz file\n",
    "canica_components_img = nib.load('E:/ADHD200/canica_resting_state.nii.gz')\n",
    "\n",
    "# get the data as a numpy array\n",
    "canica_components_numpy= canica_components_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33d112",
   "metadata": {},
   "source": [
    "# Print all ICA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b75c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_prob_atlas\n",
    "\n",
    "# Plot all ICA components together\n",
    "plot_prob_atlas(canica_components_img, title='All ICA components')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e00a1a",
   "metadata": {},
   "source": [
    "# ROI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.regions import RegionExtractor\n",
    "from nilearn import plotting\n",
    "extractor = RegionExtractor(canica_components_img , threshold=0.5,\n",
    "                            thresholding_strategy='ratio_n_voxels',\n",
    "                            extractor='local_regions',\n",
    "                            standardize=True, min_region_size=1350)\n",
    "# Just call fit() to process for regions extraction\n",
    "extractor.fit()\n",
    "# Extracted regions are stored in regions_img_\n",
    "regions_extracted_img = extractor.regions_img_\n",
    "# Each region index is stored in index_\n",
    "regions_index = extractor.index_\n",
    "# Total number of regions extracted\n",
    "n_regions_extracted = regions_extracted_img.shape[-1]\n",
    "\n",
    "# Visualization of region extraction results\n",
    "# title = ('%d regions are extracted from %d components.'\n",
    "#          '\\nEach separate color of region indicates extracted region'\n",
    "#          % (n_regions_extracted,20))\n",
    "plotting.plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map\n",
    "\n",
    "# Get the number of images\n",
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "num_rows = 4  # Adjust as needed\n",
    "num_cols = 5\n",
    "\n",
    "# Create the subplot grid\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))  # Adjust figsize as needed\n",
    "\n",
    "# Iterate over the images and plot them in the subplots\n",
    "for i, cur_img in enumerate(iter_img(canica_components_img)):\n",
    "    # Calculate the subplot index\n",
    "    row_index = i // num_cols\n",
    "    col_index = i % num_cols\n",
    "\n",
    "    # Plot the image in the corresponding subplot\n",
    "    ax = axes[row_index, col_index] if num_rows > 1 else axes[col_index]\n",
    "    plot_stat_map(\n",
    "        cur_img,\n",
    "        display_mode=\"z\",\n",
    "        title=f\"Comp {int(i)}\",\n",
    "        cut_coords=1,\n",
    "        colorbar=False,\n",
    "        axes=ax\n",
    "    )\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee235721",
   "metadata": {},
   "source": [
    "# Time series data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "all_data=[]\n",
    "for filename  in adhd_motion_spatial:\n",
    "    time_series = extractor.transform(filename)\n",
    "    all_data.append(time_series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5269eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"E:/ADHD200/ICA_times_series_905.npy\",all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
